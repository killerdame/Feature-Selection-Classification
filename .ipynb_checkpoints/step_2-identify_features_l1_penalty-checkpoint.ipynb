{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - Identify Salient Features Using $\\ell1$-penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE: EACH OF THESE SHOULD BE WRITTEN SOLELY WITH REGARD TO STEP 2 - Identify Features**\n",
    "\n",
    "### Domain and Data\n",
    "\n",
    "**TODO:** Write a simple statement about the domain of your problem and the dataset upon which you will be working. \n",
    "\n",
    "### Problem Statement\n",
    "\n",
    "**TODO:** Write a simple problem statement with regard to identifying features only.\n",
    "\n",
    "### Solution Statement\n",
    "\n",
    "**TODO:** Write a simple solution statement with regard to identifying features only.\n",
    "\n",
    "### Metric\n",
    "\n",
    "**TODO**: Write a statement about the metric you will be using. This is with regard to identifying features. This is the metric that will show you whether or not a feature is important. Provide a brief justification for choosing this metric.\n",
    "\n",
    "### Benchmark\n",
    "\n",
    "**TODO**: This may or may not directly connect to your metric. It would be good here to provide a statement about how many feautures you might be looking for. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Domain and Data : \n",
    "\n",
    "MADELON is an artificial dataset containing data points grouped in 32 clusters placed on the vertices of a five dimensional hypercube and randomly labeled +1 or -1. The five dimensions constitute 5 informative features. 15 linear combinations of those features were added to form a set of 20 (redundant) informative features. Based on those 20 features one must separate the examples into the 2 classes (corresponding to the +-1 labels). We added a number of distractor feature called 'probes' having no predictive power. The order of the features and patterns were randomized.\n",
    "\n",
    "Problem Statement:\n",
    "\n",
    "For this stage of the project my task is to identify salient features.\n",
    "\n",
    "Solution Statement: \n",
    "\n",
    "I will use a logistic regression with an L1 penatly in an attempt to reduce the noise of the dataset and identify salient features. \n",
    "\n",
    "Metric:\n",
    "I will be using Accuracy, Precision, Recall, and F1-Score.\n",
    "\n",
    "Benchmark:\n",
    "I am attempting to identify no more than 30 features with a test score greater than 52%.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "Implement the following code pipeline using the functions you write in `lib/project_5.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"assets/identify_features.png\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lib.project_5 import load_data_from_database, make_data_dict, general_model, general_transformer, add_to_process_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = load_data_from_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# del df['index']\n",
    "# X = df.drop(['label'],axis=1)\n",
    "# y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_dict = make_data_dict(df, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "data_dict = general_transformer(StandardScaler(), data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': LogisticRegression(C=0.024, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "           penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
       "           verbose=0, warm_start=False),\n",
       " 'test_score': 0.61599999999999999,\n",
       " 'train_score': 0.6333333333333333}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model_dict = general_model(LogisticRegression(penalty='l1', random_state=42, C=.024), data_dict)\n",
    "model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'index', 0.0),\n",
       " (u'feat_000', 0.0),\n",
       " (u'feat_001', 0.0),\n",
       " (u'feat_002', 0.0),\n",
       " (u'feat_003', 0.0),\n",
       " (u'feat_004', 0.0),\n",
       " (u'feat_005', 0.0),\n",
       " (u'feat_006', 0.0),\n",
       " (u'feat_007', 0.0),\n",
       " (u'feat_008', 0.0),\n",
       " (u'feat_009', 0.0),\n",
       " (u'feat_010', 0.0),\n",
       " (u'feat_011', 0.0),\n",
       " (u'feat_012', 0.0),\n",
       " (u'feat_013', 0.0),\n",
       " (u'feat_014', 0.0),\n",
       " (u'feat_015', 0.0),\n",
       " (u'feat_016', 0.0),\n",
       " (u'feat_017', 0.0),\n",
       " (u'feat_018', 0.0),\n",
       " (u'feat_019', 0.0),\n",
       " (u'feat_020', 0.0),\n",
       " (u'feat_021', 0.0),\n",
       " (u'feat_022', 0.0),\n",
       " (u'feat_023', 0.0),\n",
       " (u'feat_024', 0.0),\n",
       " (u'feat_025', 0.0),\n",
       " (u'feat_026', 0.0),\n",
       " (u'feat_027', 0.0),\n",
       " (u'feat_028', 0.0),\n",
       " (u'feat_029', 0.0),\n",
       " (u'feat_030', 0.0),\n",
       " (u'feat_031', 0.0),\n",
       " (u'feat_032', 0.0),\n",
       " (u'feat_033', 0.0),\n",
       " (u'feat_034', 0.0),\n",
       " (u'feat_035', 0.0),\n",
       " (u'feat_036', 0.0),\n",
       " (u'feat_037', 0.0),\n",
       " (u'feat_038', 0.0),\n",
       " (u'feat_039', 0.0),\n",
       " (u'feat_040', 0.0),\n",
       " (u'feat_041', 0.0),\n",
       " (u'feat_042', 0.0),\n",
       " (u'feat_043', 0.0),\n",
       " (u'feat_044', 0.0),\n",
       " (u'feat_045', 0.0),\n",
       " (u'feat_046', 0.0),\n",
       " (u'feat_047', 0.0),\n",
       " (u'feat_048', 0.10901853843138913),\n",
       " (u'feat_049', 0.0),\n",
       " (u'feat_050', 0.0),\n",
       " (u'feat_051', 0.0),\n",
       " (u'feat_052', 0.0),\n",
       " (u'feat_053', 0.0),\n",
       " (u'feat_054', 0.0),\n",
       " (u'feat_055', 0.0),\n",
       " (u'feat_056', 0.0),\n",
       " (u'feat_057', 0.0),\n",
       " (u'feat_058', 0.0),\n",
       " (u'feat_059', 0.0),\n",
       " (u'feat_060', 0.0),\n",
       " (u'feat_061', 0.0),\n",
       " (u'feat_062', 0.0),\n",
       " (u'feat_063', 0.0),\n",
       " (u'feat_064', 0.0),\n",
       " (u'feat_065', 0.0),\n",
       " (u'feat_066', 0.0),\n",
       " (u'feat_067', 0.0),\n",
       " (u'feat_068', 0.0),\n",
       " (u'feat_069', 0.0),\n",
       " (u'feat_070', 0.0),\n",
       " (u'feat_071', 0.0),\n",
       " (u'feat_072', 0.0),\n",
       " (u'feat_073', 0.0),\n",
       " (u'feat_074', 0.0),\n",
       " (u'feat_075', 0.0),\n",
       " (u'feat_076', 0.0),\n",
       " (u'feat_077', 0.0),\n",
       " (u'feat_078', 0.0),\n",
       " (u'feat_079', 0.0),\n",
       " (u'feat_080', 0.0),\n",
       " (u'feat_081', 0.0),\n",
       " (u'feat_082', 0.0),\n",
       " (u'feat_083', 0.0),\n",
       " (u'feat_084', 0.0),\n",
       " (u'feat_085', 0.0),\n",
       " (u'feat_086', 0.0),\n",
       " (u'feat_087', 0.0),\n",
       " (u'feat_088', 0.0),\n",
       " (u'feat_089', 0.0),\n",
       " (u'feat_090', 0.0),\n",
       " (u'feat_091', 0.0),\n",
       " (u'feat_092', 0.0),\n",
       " (u'feat_093', 0.0),\n",
       " (u'feat_094', 0.0),\n",
       " (u'feat_095', 0.0),\n",
       " (u'feat_096', 0.0),\n",
       " (u'feat_097', 0.0),\n",
       " (u'feat_098', 0.0),\n",
       " (u'feat_099', 0.0),\n",
       " (u'feat_100', 0.0),\n",
       " (u'feat_101', 0.0),\n",
       " (u'feat_102', 0.0),\n",
       " (u'feat_103', 0.0),\n",
       " (u'feat_104', 0.0),\n",
       " (u'feat_105', 0.0),\n",
       " (u'feat_106', 0.0),\n",
       " (u'feat_107', 0.0),\n",
       " (u'feat_108', 0.0),\n",
       " (u'feat_109', 0.0),\n",
       " (u'feat_110', 0.0),\n",
       " (u'feat_111', 0.0),\n",
       " (u'feat_112', 0.0),\n",
       " (u'feat_113', 0.0),\n",
       " (u'feat_114', 0.0),\n",
       " (u'feat_115', 0.0),\n",
       " (u'feat_116', 0.0),\n",
       " (u'feat_117', 0.0),\n",
       " (u'feat_118', 0.0),\n",
       " (u'feat_119', 0.0023528523731166525),\n",
       " (u'feat_120', 0.0),\n",
       " (u'feat_121', 0.0),\n",
       " (u'feat_122', 0.0),\n",
       " (u'feat_123', 0.0),\n",
       " (u'feat_124', 0.0),\n",
       " (u'feat_125', 0.0),\n",
       " (u'feat_126', 0.0),\n",
       " (u'feat_127', 0.0),\n",
       " (u'feat_128', 0.0),\n",
       " (u'feat_129', 0.0),\n",
       " (u'feat_130', 0.0),\n",
       " (u'feat_131', 0.0),\n",
       " (u'feat_132', 0.0),\n",
       " (u'feat_133', 0.0),\n",
       " (u'feat_134', 0.0),\n",
       " (u'feat_135', 0.0),\n",
       " (u'feat_136', 0.0),\n",
       " (u'feat_137', 0.00041053631337142552),\n",
       " (u'feat_138', 0.0),\n",
       " (u'feat_139', 0.0),\n",
       " (u'feat_140', 0.0),\n",
       " (u'feat_141', 0.0),\n",
       " (u'feat_142', 0.0),\n",
       " (u'feat_143', 0.0),\n",
       " (u'feat_144', 0.0),\n",
       " (u'feat_145', 0.0),\n",
       " (u'feat_146', 0.0),\n",
       " (u'feat_147', 0.0),\n",
       " (u'feat_148', 0.0),\n",
       " (u'feat_149', 0.0),\n",
       " (u'feat_150', 0.0),\n",
       " (u'feat_151', 0.0),\n",
       " (u'feat_152', 0.0),\n",
       " (u'feat_153', 0.0),\n",
       " (u'feat_154', 0.0),\n",
       " (u'feat_155', 0.0),\n",
       " (u'feat_156', 0.0),\n",
       " (u'feat_157', 0.0),\n",
       " (u'feat_158', 0.0),\n",
       " (u'feat_159', 0.0),\n",
       " (u'feat_160', 0.0),\n",
       " (u'feat_161', 0.0),\n",
       " (u'feat_162', 0.0),\n",
       " (u'feat_163', 0.0),\n",
       " (u'feat_164', 0.0),\n",
       " (u'feat_165', 0.0),\n",
       " (u'feat_166', 0.0),\n",
       " (u'feat_167', 0.0),\n",
       " (u'feat_168', 0.0),\n",
       " (u'feat_169', 0.0),\n",
       " (u'feat_170', 0.0),\n",
       " (u'feat_171', 0.0),\n",
       " (u'feat_172', 0.0),\n",
       " (u'feat_173', 0.0),\n",
       " (u'feat_174', 0.0),\n",
       " (u'feat_175', 0.0),\n",
       " (u'feat_176', 0.0),\n",
       " (u'feat_177', 0.0),\n",
       " (u'feat_178', 0.0),\n",
       " (u'feat_179', 0.0),\n",
       " (u'feat_180', 0.0),\n",
       " (u'feat_181', 0.0),\n",
       " (u'feat_182', 0.0),\n",
       " (u'feat_183', 0.0),\n",
       " (u'feat_184', 0.0),\n",
       " (u'feat_185', 0.0),\n",
       " (u'feat_186', 0.0),\n",
       " (u'feat_187', 0.0),\n",
       " (u'feat_188', 0.0),\n",
       " (u'feat_189', 0.0),\n",
       " (u'feat_190', 0.0),\n",
       " (u'feat_191', 0.0),\n",
       " (u'feat_192', 0.0),\n",
       " (u'feat_193', 0.0),\n",
       " (u'feat_194', 0.0),\n",
       " (u'feat_195', 0.0),\n",
       " (u'feat_196', 0.0),\n",
       " (u'feat_197', 0.0),\n",
       " (u'feat_198', 0.0),\n",
       " (u'feat_199', 0.0),\n",
       " (u'feat_200', 0.0),\n",
       " (u'feat_201', 0.0),\n",
       " (u'feat_202', 0.0),\n",
       " (u'feat_203', 0.0),\n",
       " (u'feat_204', 0.022551191392236523),\n",
       " (u'feat_205', 0.0),\n",
       " (u'feat_206', 0.0),\n",
       " (u'feat_207', 0.0),\n",
       " (u'feat_208', 0.0),\n",
       " (u'feat_209', 0.0),\n",
       " (u'feat_210', 0.0),\n",
       " (u'feat_211', 0.0),\n",
       " (u'feat_212', 0.0),\n",
       " (u'feat_213', 0.0),\n",
       " (u'feat_214', 0.0),\n",
       " (u'feat_215', 0.0),\n",
       " (u'feat_216', 0.0),\n",
       " (u'feat_217', 0.0),\n",
       " (u'feat_218', 0.0),\n",
       " (u'feat_219', 0.0),\n",
       " (u'feat_220', 0.0),\n",
       " (u'feat_221', 0.0),\n",
       " (u'feat_222', 0.0),\n",
       " (u'feat_223', 0.0),\n",
       " (u'feat_224', 0.0),\n",
       " (u'feat_225', 0.0),\n",
       " (u'feat_226', 0.0),\n",
       " (u'feat_227', 0.0),\n",
       " (u'feat_228', 0.0),\n",
       " (u'feat_229', 0.0),\n",
       " (u'feat_230', 0.0),\n",
       " (u'feat_231', 0.0),\n",
       " (u'feat_232', 0.0),\n",
       " (u'feat_233', 0.0),\n",
       " (u'feat_234', 0.0),\n",
       " (u'feat_235', 0.0),\n",
       " (u'feat_236', 0.0),\n",
       " (u'feat_237', 0.0),\n",
       " (u'feat_238', 0.0),\n",
       " (u'feat_239', 0.0),\n",
       " (u'feat_240', 0.0),\n",
       " (u'feat_241', 0.044807199967716975),\n",
       " (u'feat_242', 0.0),\n",
       " (u'feat_243', 0.0),\n",
       " (u'feat_244', 0.0),\n",
       " (u'feat_245', 0.0),\n",
       " (u'feat_246', 0.0),\n",
       " (u'feat_247', 0.0),\n",
       " (u'feat_248', 0.0),\n",
       " (u'feat_249', 0.0),\n",
       " (u'feat_250', 0.0),\n",
       " (u'feat_251', 0.0),\n",
       " (u'feat_252', 0.0),\n",
       " (u'feat_253', 0.0),\n",
       " (u'feat_254', 0.0),\n",
       " (u'feat_255', 0.0),\n",
       " (u'feat_256', 0.0),\n",
       " (u'feat_257', 0.0),\n",
       " (u'feat_258', 0.0),\n",
       " (u'feat_259', 0.0),\n",
       " (u'feat_260', 0.0),\n",
       " (u'feat_261', 0.0),\n",
       " (u'feat_262', 0.0),\n",
       " (u'feat_263', 0.0),\n",
       " (u'feat_264', 0.0),\n",
       " (u'feat_265', 0.0),\n",
       " (u'feat_266', 0.0),\n",
       " (u'feat_267', 0.0),\n",
       " (u'feat_268', 0.0),\n",
       " (u'feat_269', 0.0),\n",
       " (u'feat_270', 0.0),\n",
       " (u'feat_271', 0.0),\n",
       " (u'feat_272', 0.0),\n",
       " (u'feat_273', 0.0),\n",
       " (u'feat_274', 0.0),\n",
       " (u'feat_275', 0.0),\n",
       " (u'feat_276', 0.0),\n",
       " (u'feat_277', 0.0),\n",
       " (u'feat_278', 0.0),\n",
       " (u'feat_279', 0.0),\n",
       " (u'feat_280', 0.0),\n",
       " (u'feat_281', 0.0),\n",
       " (u'feat_282', 0.0),\n",
       " (u'feat_283', 0.0),\n",
       " (u'feat_284', 0.0),\n",
       " (u'feat_285', 0.0),\n",
       " (u'feat_286', 0.0),\n",
       " (u'feat_287', 0.0),\n",
       " (u'feat_288', 0.0),\n",
       " (u'feat_289', 0.0),\n",
       " (u'feat_290', 0.0),\n",
       " (u'feat_291', 0.0),\n",
       " (u'feat_292', 0.0),\n",
       " (u'feat_293', 0.0),\n",
       " (u'feat_294', 0.0),\n",
       " (u'feat_295', 0.0),\n",
       " (u'feat_296', 0.0),\n",
       " (u'feat_297', 0.0),\n",
       " (u'feat_298', 0.0),\n",
       " (u'feat_299', 0.0),\n",
       " (u'feat_300', 0.0),\n",
       " (u'feat_301', 0.0),\n",
       " (u'feat_302', 0.0),\n",
       " (u'feat_303', 0.0),\n",
       " (u'feat_304', 0.0),\n",
       " (u'feat_305', 0.0),\n",
       " (u'feat_306', 0.0),\n",
       " (u'feat_307', 0.0),\n",
       " (u'feat_308', 0.0),\n",
       " (u'feat_309', 0.0),\n",
       " (u'feat_310', 0.0),\n",
       " (u'feat_311', 0.0),\n",
       " (u'feat_312', 0.0),\n",
       " (u'feat_313', 0.0),\n",
       " (u'feat_314', 0.0),\n",
       " (u'feat_315', 0.0),\n",
       " (u'feat_316', 0.0),\n",
       " (u'feat_317', 0.0),\n",
       " (u'feat_318', 0.0),\n",
       " (u'feat_319', 0.0),\n",
       " (u'feat_320', 0.0),\n",
       " (u'feat_321', 0.0),\n",
       " (u'feat_322', 0.0),\n",
       " (u'feat_323', -0.02275147730228692),\n",
       " (u'feat_324', 0.0),\n",
       " (u'feat_325', 0.0),\n",
       " (u'feat_326', 0.0),\n",
       " (u'feat_327', 0.0),\n",
       " (u'feat_328', 0.0),\n",
       " (u'feat_329', 0.0),\n",
       " (u'feat_330', 0.0),\n",
       " (u'feat_331', 0.0),\n",
       " (u'feat_332', 0.0),\n",
       " (u'feat_333', 0.00069610667901397639),\n",
       " (u'feat_334', 0.0),\n",
       " (u'feat_335', 0.0),\n",
       " (u'feat_336', 0.0),\n",
       " (u'feat_337', 0.0),\n",
       " (u'feat_338', 0.0),\n",
       " (u'feat_339', 0.0),\n",
       " (u'feat_340', 0.0),\n",
       " (u'feat_341', 0.0),\n",
       " (u'feat_342', 0.0),\n",
       " (u'feat_343', 0.0),\n",
       " (u'feat_344', 0.0),\n",
       " (u'feat_345', 0.0),\n",
       " (u'feat_346', 0.0),\n",
       " (u'feat_347', 0.0),\n",
       " (u'feat_348', 0.0),\n",
       " (u'feat_349', 0.0),\n",
       " (u'feat_350', 0.0),\n",
       " (u'feat_351', 0.0),\n",
       " (u'feat_352', 0.0),\n",
       " (u'feat_353', 0.0),\n",
       " (u'feat_354', 0.0),\n",
       " (u'feat_355', 0.0),\n",
       " (u'feat_356', 0.0),\n",
       " (u'feat_357', 0.0),\n",
       " (u'feat_358', 0.0),\n",
       " (u'feat_359', 0.0),\n",
       " (u'feat_360', 0.0),\n",
       " (u'feat_361', 0.0),\n",
       " (u'feat_362', 0.0),\n",
       " (u'feat_363', 0.0),\n",
       " (u'feat_364', 0.0),\n",
       " (u'feat_365', 0.0),\n",
       " (u'feat_366', 0.0),\n",
       " (u'feat_367', 0.0),\n",
       " (u'feat_368', 0.0),\n",
       " (u'feat_369', 0.0),\n",
       " (u'feat_370', 0.0),\n",
       " (u'feat_371', 0.0),\n",
       " (u'feat_372', 0.0),\n",
       " (u'feat_373', 0.0),\n",
       " (u'feat_374', 0.0),\n",
       " (u'feat_375', 0.0),\n",
       " (u'feat_376', 0.0),\n",
       " (u'feat_377', 0.0),\n",
       " (u'feat_378', 0.0),\n",
       " (u'feat_379', 0.0),\n",
       " (u'feat_380', 0.0),\n",
       " (u'feat_381', 0.0),\n",
       " (u'feat_382', 0.0),\n",
       " (u'feat_383', 0.0),\n",
       " (u'feat_384', 0.0),\n",
       " (u'feat_385', 0.0),\n",
       " (u'feat_386', 0.0),\n",
       " (u'feat_387', 0.0),\n",
       " (u'feat_388', 0.0),\n",
       " (u'feat_389', 0.0),\n",
       " (u'feat_390', 0.0),\n",
       " (u'feat_391', 0.0),\n",
       " (u'feat_392', 0.0),\n",
       " (u'feat_393', 0.0),\n",
       " (u'feat_394', 0.0),\n",
       " (u'feat_395', 0.0),\n",
       " (u'feat_396', 0.0),\n",
       " (u'feat_397', 0.0),\n",
       " (u'feat_398', 0.0),\n",
       " (u'feat_399', 0.0),\n",
       " (u'feat_400', 0.0),\n",
       " (u'feat_401', 0.0),\n",
       " (u'feat_402', 0.0),\n",
       " (u'feat_403', 0.0),\n",
       " (u'feat_404', 0.0),\n",
       " (u'feat_405', 0.0),\n",
       " (u'feat_406', 0.0),\n",
       " (u'feat_407', 0.0),\n",
       " (u'feat_408', 0.0),\n",
       " (u'feat_409', 0.0),\n",
       " (u'feat_410', 0.0),\n",
       " (u'feat_411', 0.0),\n",
       " (u'feat_412', 0.0),\n",
       " (u'feat_413', 0.0),\n",
       " (u'feat_414', 0.0),\n",
       " (u'feat_415', 0.0),\n",
       " (u'feat_416', 0.0),\n",
       " (u'feat_417', 0.0),\n",
       " (u'feat_418', 0.0),\n",
       " (u'feat_419', 0.0),\n",
       " (u'feat_420', -0.0046794963244760623),\n",
       " (u'feat_421', 0.0),\n",
       " (u'feat_422', 0.0),\n",
       " (u'feat_423', 0.0),\n",
       " (u'feat_424', 0.063554513550390476),\n",
       " (u'feat_425', 0.0),\n",
       " (u'feat_426', 0.0),\n",
       " (u'feat_427', 0.0),\n",
       " (u'feat_428', 0.0),\n",
       " (u'feat_429', 0.0),\n",
       " (u'feat_430', 0.0),\n",
       " (u'feat_431', 0.048180520290436464),\n",
       " (u'feat_432', 0.0),\n",
       " (u'feat_433', 0.0),\n",
       " (u'feat_434', 0.0),\n",
       " (u'feat_435', 0.0),\n",
       " (u'feat_436', 0.0),\n",
       " (u'feat_437', 0.0),\n",
       " (u'feat_438', 0.0),\n",
       " (u'feat_439', 0.0),\n",
       " (u'feat_440', 0.0),\n",
       " (u'feat_441', 0.0),\n",
       " (u'feat_442', 0.0),\n",
       " (u'feat_443', 0.0),\n",
       " (u'feat_444', 0.0),\n",
       " (u'feat_445', 0.0),\n",
       " (u'feat_446', 0.0),\n",
       " (u'feat_447', 0.0),\n",
       " (u'feat_448', 0.0),\n",
       " (u'feat_449', 0.0),\n",
       " (u'feat_450', 0.0),\n",
       " (u'feat_451', 0.0),\n",
       " (u'feat_452', 0.0),\n",
       " (u'feat_453', 0.0),\n",
       " (u'feat_454', 0.0),\n",
       " (u'feat_455', 0.0),\n",
       " (u'feat_456', 0.0),\n",
       " (u'feat_457', 0.0),\n",
       " (u'feat_458', 0.0),\n",
       " (u'feat_459', 0.0),\n",
       " (u'feat_460', 0.0),\n",
       " (u'feat_461', 0.0),\n",
       " (u'feat_462', 0.0),\n",
       " (u'feat_463', 0.0),\n",
       " (u'feat_464', 0.0),\n",
       " (u'feat_465', 0.0),\n",
       " (u'feat_466', 0.0),\n",
       " (u'feat_467', 0.0),\n",
       " (u'feat_468', 0.0),\n",
       " (u'feat_469', 0.0),\n",
       " (u'feat_470', 0.0),\n",
       " (u'feat_471', 0.0),\n",
       " (u'feat_472', 0.0),\n",
       " (u'feat_473', 0.0),\n",
       " (u'feat_474', 0.0),\n",
       " (u'feat_475', 0.29476835102533899),\n",
       " (u'feat_476', 0.0),\n",
       " (u'feat_477', 0.0),\n",
       " (u'feat_478', 0.0),\n",
       " (u'feat_479', 0.0),\n",
       " (u'feat_480', 0.0),\n",
       " (u'feat_481', -0.0049083503769845821),\n",
       " (u'feat_482', 0.0),\n",
       " (u'feat_483', 0.0),\n",
       " (u'feat_484', 0.0),\n",
       " (u'feat_485', 0.0),\n",
       " (u'feat_486', 0.0),\n",
       " (u'feat_487', 0.0),\n",
       " (u'feat_488', 0.0),\n",
       " (u'feat_489', 0.0),\n",
       " (u'feat_490', 0.0),\n",
       " (u'feat_491', 0.0),\n",
       " (u'feat_492', 0.0),\n",
       " (u'feat_493', 0.0),\n",
       " (u'feat_494', 0.0),\n",
       " (u'feat_495', 0.0),\n",
       " (u'feat_496', -0.021521752281481808),\n",
       " (u'feat_497', 0.0),\n",
       " (u'feat_498', 0.0),\n",
       " (u'feat_499', 0.0)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(['label'],axis=1)\n",
    "model_coef = model_dict['model'].coef_ \n",
    "model_col = X.columns\n",
    "total_features = zip(model_col, model_coef[0])\n",
    "total_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'feat_048', 0.10901853843138913),\n",
       " (u'feat_119', 0.0023528523731166525),\n",
       " (u'feat_137', 0.00041053631337142552),\n",
       " (u'feat_204', 0.022551191392236523),\n",
       " (u'feat_241', 0.044807199967716975),\n",
       " (u'feat_323', -0.02275147730228692),\n",
       " (u'feat_333', 0.00069610667901397639),\n",
       " (u'feat_420', -0.0046794963244760623),\n",
       " (u'feat_424', 0.063554513550390476),\n",
       " (u'feat_431', 0.048180520290436464),\n",
       " (u'feat_475', 0.29476835102533899),\n",
       " (u'feat_481', -0.0049083503769845821),\n",
       " (u'feat_496', -0.021521752281481808)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_feat = [i for i in total_features if i[1] > 0.0 or i[1] < 0.0]\n",
    "lr_feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### My test score is .616, I am left with 13 features with a L1 Logistic Regression and a C parameter of .024."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
